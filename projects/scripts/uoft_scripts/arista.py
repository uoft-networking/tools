from time import sleep
import typing as t

from pexpect import TIMEOUT
from pynautobot import RequestError
from uoft_core.console import console
from uoft_ssh.cli import get_ssh_session
from uoft_ssh import Settings as SSHSettings
from uoft_core import logging
from uoft_core import BaseSettings, SecretStr

if t.TYPE_CHECKING:
    from uoft_ssh.pexpect_utils import UofTPexpectSpawn
    from pynautobot.models.dcim import Devices
    from pynautobot.models.extras import Record

class Settings(BaseSettings):
    cvp_token: SecretStr

    class Config(BaseSettings.Config):
        app_name = "arista"

logger = logging.getLogger(__name__)


def _get_ssh_session(
    terminal_server: str,
    port: int,
):
    creds = SSHSettings.from_cache().terminal_server
    username = f"{creds.username}:port{port}"

    ssh = get_ssh_session(
        host=terminal_server,
        username=username,
        password=creds.password.get_secret_value(),
    )

    return ssh


def _get_onboarding_token():
    "Generate a CVP onboarding token"
    # WARNING: here be dragons
    # All the code in the first half of this function is autogenerated by the protobuf compiler,
    # and then slimmed down to just the bits we need to use.
    # The original protobug python code was generated using the following commands:
    # to aquire .proto file: ```
    #   grpcurl -H 'access_token: <TOKEN>' -proto-out-dir . \
    #   www.cv-prod-na-northeast1-b.arista.io:443 \
    #   describe admin.Enrollment.AddEnrollmentToken
    # ```
    # to compile into python:
    # ```
    #   uv run --with 'grpcio-tools==1.71.0' --with 'protobuf>=6' \
    #   python -m grpc_tools.protoc --python_out . --grpc_python_out . -I . enrollment.proto
    # ```
    import grpc
    from google.protobuf import descriptor as _descriptor
    from google.protobuf import descriptor_pool as _descriptor_pool
    from google.protobuf.internal import builder as _builder
    from google.protobuf import field_mask_pb2  # type: ignore  # noqa: F401
    from google.protobuf import duration_pb2

    _globals = globals()

    _globals["DESCRIPTOR"] = _descriptor_pool.Default().AddSerializedFile(
        b'\n\x10\x65nrollment.proto\x12\x05\x61\x64min\x1a \
        google/protobuf/field_mask.proto\x1a\x1egoogle/protobuf/duration.proto\
        "\xa6\x01\n\x0f\x45nrollmentToken\x12\r\n\x05token\x18\x01 \
        \x01(\t\x12\x0e\n\x06groups\x18\x02 \x03(\t\x12\x17\n\x0freenrollDevices\
        \x18\x03 \x03(\t\x12+\n\x08validFor\x18\x04 \x01(\x0b\x32\x19.google.protobuf.Duration\
        \x12.\n\nfield_mask\x18\x64 \x01(\x0b\x32\x1a.google.protobuf.FieldMask"L\
        \n\x19\x41\x64\x64\x45nrollmentTokenRequest\x12/\n\x0f\x65nrollmentToken\x18\x01 \
        \x01(\x0b\x32\x16.admin.EnrollmentToken"M\n\x1a\x41\x64\x64\x45nrollmentTokenResponse\x12\
        /\n\x0f\x65nrollmentToken\x18\x01 \x01(\x0b\x32\x16.admin.EnrollmentTokenB+Z)arista/\
        aeris/service/admin/enrollment/genb\x06proto3'
    )

    _builder.BuildMessageAndEnumDescriptors(_globals["DESCRIPTOR"], _globals)
    _builder.BuildTopDescriptorsAndMessages(_globals["DESCRIPTOR"], "enrollment_pb2", _globals)
    if not _descriptor._USE_C_DESCRIPTORS:
        _globals["DESCRIPTOR"]._loaded_options = None
        _globals["DESCRIPTOR"]._serialized_options = b"Z)arista/aeris/service/admin/enrollment/gen"
        _globals["_ENROLLMENTTOKEN"]._serialized_start = 94
        _globals["_ENROLLMENTTOKEN"]._serialized_end = 260
        _globals["_ADDENROLLMENTTOKENREQUEST"]._serialized_start = 262
        _globals["_ADDENROLLMENTTOKENREQUEST"]._serialized_end = 338
        _globals["_ADDENROLLMENTTOKENRESPONSE"]._serialized_start = 340
        _globals["_ADDENROLLMENTTOKENRESPONSE"]._serialized_end = 417

    # Ok, now we've got dynamically generated python classes for the protobuf messages
    # we need to use to call the CVP gRPC API.
    # Now we can actually use them to call the API.
    s = Settings.from_cache()

    token_request = _globals["AddEnrollmentTokenRequest"](  # pyright: ignore[reportAttributeAccessIssue]
        enrollmentToken=_globals["EnrollmentToken"](  # pyright: ignore[reportAttributeAccessIssue]
            validFor=duration_pb2.Duration(seconds=60 * 60 * 4)  # 4 hours
        )
    )

    credentials = grpc.composite_channel_credentials(
        grpc.ssl_channel_credentials(),
        grpc.access_token_call_credentials(s.cvp_token.get_secret_value()),
    )
    # Create a gRPC channel
    channel = grpc.secure_channel(target="www.cv-prod-na-northeast1-b.arista.io:443", credentials=credentials)

    # Create a bound method for the gRPC call
    method = channel.unary_unary(
        "/admin.Enrollment/AddEnrollmentToken",
        request_serializer=_globals["AddEnrollmentTokenRequest"].SerializeToString,
        response_deserializer=_globals["AddEnrollmentTokenResponse"].FromString,
    )

    return method(request=token_request).enrollmentToken.token


def _put_switch_in_config_mode(ssh: "UofTPexpectSpawn"):
    """
    Given an open pexpect session to a port on a terminal server,
    take the switch attached to that port from whatever state it's currently in
    and put it into config mode
    """

    ssh.multi_expect(timeout=5)

    @ssh.multi_expect.register(ssh.TIMEOUT)
    def _():
        logger.info("Terminal server not yet ready, going to poke it and wait some more...")
        ssh.sendline("")
        return ssh.multi_expect.reenter_loop()

    @ssh.multi_expect.register(r"Press RETURN to get started.")
    def _():
        logger.info("Switch is now available and responding.")
        ssh.sendline("")
        return ssh.multi_expect.reenter_loop()

    @ssh.multi_expect.register(r"Would you like to enter the initial configuration dialog?")
    def _():
        logger.info("This switch is uninitialized, and has booted into the config wizard. Cancelling the wizard...")
        ssh.sendline("no")
        return ssh.multi_expect.reenter_loop()

    @ssh.multi_expect.register(r"Switch>")
    def _():
        logger.info("This switch is uninitialized. Entering enable mode now...")
        ssh.sendline("enable")
        sleep(1)
        return ssh.multi_expect.reenter_loop()

    @ssh.multi_expect.register(r"Zero Touch Provisioning mode")
    def _():
        logger.info("This switch is uninitialized and in ZTP mode. Logging in and disabling ZTP...")
        ssh.expect(r"localhost login:")
        ssh.sendline("admin")
        ssh.expect(r"localhost>")
        ssh.sendline("zerotouch disable")
        logger.info("ZTP disabled, rebooting switch...")
        ssh.expect(r"Restarting system")
        sleep(120)
        # When switch reboots, it sometimes prints undecodable bytes to the terminal, like `\xff\x00`
        # This causes the expect loop to fail, so we need to set codec_errors to "replace" to ignore them
        # temporarily
        decoder = ssh._decoder  # pyright: ignore[reportAttributeAccessIssue]
        decoder.errors = "replace"
        ssh.expect("Aboot")  # Once we see this, we know the switch is booting back up and can replace the codec_errors
        decoder.errors = ssh.codec_errors
        logger.debug("Switch is now booting up, waiting for it to be ready...")
        return ssh.multi_expect.reenter_loop()

    @ssh.multi_expect.register(r"localhost login:")
    def _():
        logger.info("This switch is uninitialized. Logging in now...")
        ssh.sendline("admin")
        sleep(1)
        return ssh.multi_expect.reenter_loop()

    @ssh.multi_expect.register(r"([a-zA-Z0-9-]+) login:")
    def _():
        logger.info("This appears to be a partially initialized switch. Logging in now...")
        ssh.sendline("admin")
        sleep(1)
        return ssh.multi_expect.reenter_loop()

    @ssh.multi_expect.register(r"localhost#")
    def _():
        logger.info("This (Arista?) switch is uninitialized and in enable mode. Entering config mode now...")
        ssh.sendline("terminal length 0")
        ssh.sendline("configure terminal")
        return ssh.multi_expect.reenter_loop()

    @ssh.multi_expect.register(r"([a-zA-Z0-9-]+)#")
    def _():
        logger.info("This switch is now in enable mode.")
        ssh.sendline("terminal length 0")
        ssh.sendline("configure terminal")
        return ssh.multi_expect.reenter_loop()

    @ssh.multi_expect.register(r"([a-zA-Z0-9-]+)>")
    def _():
        logger.info("We are now logged into a partially initialized switch. Entering 'enable' mode...")
        ssh.sendline("enable")
        # at this point, the switch may or may not be configured to require an enable password
        # if it is, we will get a password prompt
        res = ssh.expect([r"Password:", r"([a-zA-Z0-9-]+)#"])
        if res == 0:
            # we got a password prompt, so we need to enter the password
            logger.info("This switch requires a password to enter enable mode, entering it now...")
            ssh.sendline(SSHSettings.from_cache().enable_secret.get_secret_value())
        else:
            # we are already in enable mode, poke the switch to trigger a new line before reentering expect loop
            ssh.sendline("")
        return ssh.multi_expect.reenter_loop()

    @ssh.multi_expect.register(r"Username:")
    def _():
        logger.info("This switch has been at least partially initialized. Logging in now...")
        ssh.sendline(SSHSettings.from_cache().personal.username)
        sleep(1)
        return ssh.multi_expect.reenter_loop()

    @ssh.multi_expect.register(r"Password:")
    def _():
        logger.info("Entering switch password...")
        ssh.sendline(SSHSettings.from_cache().personal.password.get_secret_value())
        return ssh.multi_expect.reenter_loop()

    @ssh.multi_expect.register(r"([a-zA-Z0-9-]+)\(config\)#")
    def _():
        logger.info("This switch is now in config mode.")
        return

    @ssh.multi_expect.register(r"([a-zA-Z0-9-]+)\(([a-zA-Z0-9-]+)\)#")
    def _():
        logger.info("This switch is in some unknown config mode, dropping back down to enable mode...")
        ssh.sendcontrol("c")
        return ssh.multi_expect.reenter_loop()

    return ssh.multi_expect.start()


def _wait_for_switch_to_come_online(ip: str):
    """
    Wait for a switch to come online by poking it on port 22
    until it responds or times out.
    """
    import socket

    logger.info(f"Waiting for {ip} to come online...")
    while True:
        try:
            socket.create_connection((ip, 22), timeout=5)
            break
        except socket.timeout:
            logger.info(f"{ip} is not yet online, waiting 5 seconds...")
            sleep(5)
    logger.success(f"{ip} is now online!")


def _get_intended_config_from_nautobot(switch_hostname: "str | Devices") -> str:
    from .nautobot import get_api, run_job

    nb = get_api(dev=False)
    if isinstance(switch_hostname, str):
        switch = t.cast("Devices", nb.dcim.devices.get(name=switch_hostname))
    else:
        switch = switch_hostname

    def get_config_for_switch(switch):
        return t.cast(str, t.cast("Record", nb.plugins.golden_config.config_postprocessing.get(switch.id)).config)

    try:
        intended_config = get_config_for_switch(switch)
    except RequestError:
        # trigger intended config generation
        logger.info(f"Switch {switch_hostname} does not have an intended config, generating one now...")
        run_job(dev=False, job_name="Generate Intended Configurations", data=dict(device=[switch.id]))
        intended_config = get_config_for_switch(switch)
    return intended_config


def _get_minimum_viable_config(switch_hostname: "str | Devices") -> list[str]:
    from .nautobot import filter_config

    intended_config = _get_intended_config_from_nautobot(switch_hostname)
    res = filter_config(config=intended_config, filters=["vrf instance"], top_level_only=True)
    res.extend(
        filter_config(
            config=intended_config,
            filters=[
                "hostname",
                "radius-server",
                "ip radius",
                "ip address",
                "enable",
                "aaa",
                "ip route",
                "^interface Management1",
            ],
        )
    )
    res.extend(
        filter_config(
            config=intended_config,
            filters=[
                "management ssh",
            ],
            sub_filters=[
                "authentication",  # we only want the authentication mode bits, none of the ACL stuff
            ],
        )
    )
    return res


def initial_provision(switch_hostname: "str | Devices", terminal_server: str, port: int):
    """
    Given a switch hostname, terminal server, and port,
    connect to the switch via the terminal server
    and give it the minimum viable config necessary
    to get it online and accessible via SSH over OOB
    (including RADIUS auth)
    """
    from .nautobot import get_api
    from rich.progress import track

    nb = get_api(dev=False)
    if isinstance(switch_hostname, str):
        switch = nb.dcim.devices.get(name=switch_hostname)
    else:
        switch = switch_hostname
    switch = t.cast("Devices", switch)
    if not switch:
        logger.error(f"Switch {switch_hostname} not found in Nautobot")
        return

    mgmt_intf = nb.dcim.interfaces.get(device=switch.id, name="Management1")
    if not mgmt_intf:
        logger.error(f"Switch {switch_hostname} does not have a Management1 interface")
        return
    mgmt_intf = t.cast("Record", mgmt_intf)
    if not mgmt_intf.enabled:
        logger.info(f"Enabling Management1 interface on {switch_hostname}")
        mgmt_intf.update(dict(enabled=True))
    if len(mgmt_intf.ip_addresses) == 0:  # pyright: ignore[reportArgumentType]
        logger.warning(f"Switch {switch_hostname} does not have an OOB IP address assigned")
        oob_pfx = nb.ipam.prefixes.get(prefix="192.168.64.0/22")
        logger.warning(f"Assigning next available IP to {switch_hostname}")
        oob_ip = oob_pfx.available_ips.create(  # pyright: ignore[reportOptionalMemberAccess, reportAttributeAccessIssue]
            data=dict(status="Active", dns_name=f"{switch_hostname}-oob", description=f"{switch_hostname}-oob")
        )
        nb.ipam.ip_address_to_interface.create(dict(ip_address=oob_ip.id, interface=mgmt_intf.id))  # type: ignore
        switch.update(dict(primary_ip4=oob_ip.id))  # type: ignore
        logger.info(f"Assigned IP {oob_ip.address} to {switch_hostname}")
    else:
        oob_ip = t.cast(list[Record], mgmt_intf.ip_addresses)[0]  # type: ignore

    ssh = _get_ssh_session(terminal_server, port)

    _put_switch_in_config_mode(ssh)

    logger.info("Switch is now in config mode, ready to accept configuration commands.")

    # At this point, we want to deploy only the minimum viable config to the switch necessary to get it
    # online and accessible via SSH (including RADIUS auth)

    # The rest of the config can then be deployed via Nornir/SSH, much faster and more reliable than
    # trying to do it all in one go here

    # rather than try to replicate and recreate the minimum viable bits of config here, (including RADIUS keys, etc)
    # we will get the full intended config from nautobot, and filter it down to just the lines we want / care about
    minimum_config = _get_minimum_viable_config(switch_hostname)

    for line in track(minimum_config, description="Pushing config to switch...", console=console()):
        logger.debug(f"Sending command: {line}")
        ssh.sendline(line)
        res = ssh.expect([r"%.*", TIMEOUT], timeout=0.5)
        if res == 0:
            logger.error(f"Command {line} failed with error: {ssh.after}")
            raise RuntimeError(f"Command {line} failed with error: {ssh.after}")

    logger.success(
        "Switch is now ready for onboarding. It can be accessed via SSH with the admin "
        f"account at IP address {oob_ip.address} and should show up in CVP momentarily"
    )
    ssh.sendline("wr mem")


def push_nautobot_config_to_switch(switch_hostname: str):
    """
    Given a switch hostname, pull ip_address and intended config from Nautobot
    push config to switch via SSH
    """
    from .nautobot import get_api

    nb = get_api(dev=False)
    switch = t.cast(Record, nb.dcim.devices.get(name=switch_hostname))

    if not switch:
        raise ValueError(f"Switch {switch_hostname} not found in Nautobot")

    s = SSHSettings.from_cache()

    try:
        ip = t.cast(str, t.cast(Record, switch.primary_ip4).address).split("/")[0]  # type: ignore
    except Exception as e:
        logger.error(f"Switch {switch_hostname} does not have a primary IP address")
        raise ValueError(f"Switch {switch_hostname} does not have a primary IP address") from e
    logger.info(f"Switch {switch_hostname} has IP address {ip}")

    intended_config = _get_intended_config_from_nautobot(switch_hostname)
    _wait_for_switch_to_come_online(ip)

    ssh = get_ssh_session(
        host=ip,
        username=s.admin.username,
        password=s.admin.password.get_secret_value(),
        accept_unknown_host=True,
    )

    _put_switch_in_config_mode(ssh)

    for line in intended_config.splitlines():
        if line.startswith("!"):
            continue
        if line == "":
            continue
        logger.debug(f"Sending command: {line}")
        ssh.sendline(line)
        res = ssh.expect([r"%.*", TIMEOUT], timeout=0.5)
        if res == 0:
            logger.error(f"Command {line} failed with error: {ssh.after}")
            raise RuntimeError(f"Command {line} failed with error: {ssh.after}")

    onboarding_token = _get_onboarding_token()
    logger.info("Writing CVP onboarding token to file...")
    ssh.sendline("copy terminal: file:/tmp/cv-onboarding-token")
    ssh.expect("enter input")
    ssh.sendline(onboarding_token)
    ssh.sendline("")
    ssh.sendcontrol("d")
    ssh.expect("Copy completed")

    logger.info("Config pushed to switch successfully. Writing config to flash...")
    ssh.sendline("write memory")
    ssh.expect(r"#")
    logger.info("Config written to flash successfully.")
    ssh.sendline("end")
    ssh.sendline("exit")
    ssh.close()
    logger.success(f"Config pushed to {switch_hostname} successfully.")


def wipe_switch(terminal_server: str, port: int, reenable_ztp_mode: bool = False):
    """
    Given a terminal server and port,
    wipe the Arista switch attached to that port
    and reset it to factory defaults.
    This is used for testing and debugging.
    """
    ssh = _get_ssh_session(terminal_server, port)
    _put_switch_in_config_mode(ssh)
    ssh.sendline("bash")
    logger.info("erasing flash...")
    ssh.sendline("rm /mnt/flash/startup-config")  # This one might fail, but that's ok
    if reenable_ztp_mode:
        ssh.sendline("rm /mnt/flash/zerotouch-config")
    ssh.sendline("logout")
    logger.info("Rebooting switch...")
    ssh.sendline("reload")
    ssh.expect("Save?")
    ssh.sendline("no")
    ssh.expect("Proceed with reload?")
    ssh.sendline("")
    ssh.expect("Restarting system")
    logger.success("Switch has been wiped and is now rebooting")
    return


@t.no_type_check
def _cvp_onboarding():
    # This function was an excercise in frustration, and an attempt to figure out how to use the CVP gRPC API
    # to automate provisioning of a switch through cloudvision itself.
    # it was abandoned when we found out that the sections of the CVP API we needed to use were
    # simultaneously difficult to use, poorly documented, and primed to be deprecated/replaced
    # with something else in the next software release.
    # The code below is a mess, and should not be used as an example of how to use the CVP gRPC API.
    # It is here for reference only, and may be removed in the future.
    from .arista import Settings
    from uoft_core.api import APIBase
    import grpc
    from google.protobuf import wrappers_pb2 as protobuf
    from fmp import wrappers_pb2 as fmp_protobuf
    from arista.studio.v1 import services as studio_svc, models as studio_models
    from arista.workspace.v1 import workspace_pb2 as workspace_models, services as workspace_svc

    class GRPC:
        def __init__(self, token):
            self.channel = grpc.secure_channel(
                target="www.cv-prod-na-northeast1-b.arista.io:443",
                credentials=grpc.composite_channel_credentials(
                    grpc.ssl_channel_credentials(),
                    grpc.access_token_call_credentials(token),
                ),
            )

            # --- studio_svc ServiceStub wrappers ---
            class AssignedTags:
                nonlocal self
                stub = studio_svc.AssignedTagsServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(studio_svc.AssignedTagsStreamRequest())

            self.AssignedTags = AssignedTags

            class AssignedTagsConfig:
                nonlocal self
                stub = studio_svc.AssignedTagsConfigServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(studio_svc.AssignedTagsConfigStreamRequest())

            self.AssignedTagsConfig = AssignedTagsConfig

            class AutofillAction:
                nonlocal self
                stub = studio_svc.AutofillActionServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(studio_svc.AutofillActionStreamRequest())

            self.AutofillAction = AutofillAction

            class AutofillActionConfig:
                nonlocal self
                stub = studio_svc.AutofillActionConfigServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(studio_svc.AutofillActionConfigStreamRequest())

            self.AutofillActionConfig = AutofillActionConfig

            class Inputs:
                nonlocal self
                stub = studio_svc.InputsServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(studio_svc.InputsStreamRequest())

                @classmethod
                def get_one(cls, studio_id, workspace_id, paths: list[str]):
                    return cls.stub.GetOne(
                        studio_svc.InputsRequest(
                            key=studio_models.InputsKey(
                                studio_id=protobuf.StringValue(value=studio_id),
                                workspace_id=protobuf.StringValue(value=workspace_id),
                                path=fmp_protobuf.RepeatedString(values=paths),
                            )
                        )
                    )

            self.Inputs = Inputs

            class InputsConfig:
                nonlocal self
                stub = studio_svc.InputsConfigServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(studio_svc.InputsConfigStreamRequest())

            self.InputsConfig = InputsConfig

            class SecretInput:
                nonlocal self
                stub = studio_svc.SecretInputServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(studio_svc.SecretInputStreamRequest())

            self.SecretInput = SecretInput

            class Studio:
                nonlocal self
                stub = studio_svc.StudioServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(studio_svc.StudioStreamRequest())

            self.Studio = Studio

            class StudioConfig:
                nonlocal self
                stub = studio_svc.StudioConfigServiceStub(self.channel)

                @classmethod
                def get_all(cls) -> t.Generator[studio_svc.StudioConfigStreamResponse, None, None]:
                    return cls.stub.GetAll(studio_svc.StudioConfigStreamRequest())

            self.StudioConfig = StudioConfig

            class StudioSummary:
                nonlocal self
                stub = studio_svc.StudioSummaryServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(studio_svc.StudioSummaryStreamRequest())

            self.StudioSummary = StudioSummary

            # --- workspace_svc ServiceStub wrappers ---
            class Workspace:
                nonlocal self
                stub = workspace_svc.WorkspaceServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(workspace_svc.WorkspaceStreamRequest())

                @classmethod
                def get_one(cls, workspace_id):
                    return cls.stub.GetOne(
                        workspace_svc.WorkspaceStreamRequest(
                            partial_eq_filter=[
                                workspace_models.Workspace(
                                    key=workspace_models.WorkspaceKey(
                                        workspace_id=protobuf.StringValue(value=workspace_id)
                                    )
                                )
                            ]
                        )
                    )

            self.Workspace = Workspace

            class WorkspaceBuild:
                nonlocal self
                stub = workspace_svc.WorkspaceBuildServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(workspace_svc.WorkspaceBuildStreamRequest())

            self.WorkspaceBuild = WorkspaceBuild

            class WorkspaceConfig:
                nonlocal self
                stub = workspace_svc.WorkspaceConfigServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(workspace_svc.WorkspaceConfigStreamRequest())

            self.WorkspaceConfig = WorkspaceConfig

            class WorkspaceSyncConfig:
                nonlocal self
                stub = workspace_svc.WorkspaceSyncConfigServiceStub(self.channel)

                @classmethod
                def get_all(cls):
                    return cls.stub.GetAll(workspace_svc.WorkspaceSyncConfigStreamRequest())

            self.WorkspaceSyncConfig = WorkspaceSyncConfig

    class CVPAPI(APIBase):
        def __init__(self, token):
            super().__init__(base_url="https://cv-prod-na-northeast1-b.arista.io", api_root="/api")
            self.cookies.update({"access_token": token})
            self.headers.update({"Authorization": f"Bearer {token}"})
            self._grpc = None

        @property
        def grpc(self):
            if not self._grpc:
                self._grpc = GRPC(self.cookies["access_token"])
            return self._grpc

    cvp_token = Settings.from_cache().cvp_token.get_secret_value()
    cvp_api = CVPAPI(cvp_token)

    # TODO: check AutofillAction and AutofillActionConfig for a1-ev0c-arista
    # /cvpserver/inventory was a bust
    # StudioService was a bust
    # StudioConfigServer was a bust, but will be useful later
    # StudioSummaryService was a bust
    # inventory.DeviceService was a bust
    # inventory.DeviceOnboarding was a bust
    # inventory.DeviceOnboardinConfig - couldn't figure it out
    # InputsService - ALMOST there, has exactly what we need, but does not include a1-ev0c-arista
    # InputsConfigService - This is the endpoint we need to submit the data to
    # studio_topology.* - I'll be honest, i got lost here. there's so many services, 
    # with no clear indication of what they do or how to use them
    r = list([r.value for r in cvp_api.grpc.AutofillAction.get_all()])
    r2 = list([r.value for r in cvp_api.grpc.AutofillActionConfig.get_all()])
    print(r)
    print(r2)
    id = next(iter(cvp_api.grpc.StudioConfig.get_all())).value.key.studio_id.value
    id == "TOPOLOGY"
    # topology_schema = cvp_api.get("/resources/studio/v1/StudioConfig", 
    #   params={'key.studioId': 'TOPOLOGY', 'key.workspaceId': 'builtin-studios-v0.99-topology'})
    # topology_schema = topology_schema.json()['value']['inputSchema']

    # grpc_channel = grpc.secure_channel(
    #     target="www.cv-prod-na-northeast1-b.arista.io:443",
    #     credentials=grpc.composite_channel_credentials(
    #         grpc.ssl_channel_credentials(), grpc.access_token_call_credentials(access_token=cvp_token)
    #     ),
    # )
    # studio_config_stub = studio_svc.StudioConfigServiceStub(grpc_channel)
    # workspace_config_stub = workspace_svc.WorkspaceServiceStub(grpc_channel)

    my_workspace = cvp_api.grpc.Workspace.get_one(workspace_id="a1-ev0c-arista")
    topology_studio = cvp_api.grpc.Studio.get_one(studio_id="TOPOLOGY")
    print(my_workspace, topology_studio)
    # assert 'TOPOLOGY' in studios_by_id, "TOPOLOGY studio not found in CVP"
    # topology_studio = studios_by_id['TOPOLOGY']

    return r


def _debug():
    # tok = _get_onboarding_token()
    # print(tok)
    # res = _get_minimum_viable_config("a1-ev0c-arista")
    # print("\n".join(res))
    from uoft_bluecat import Settings as BluecatSettings

    with BluecatSettings.from_cache().alt_api_connection() as bc:
        net = bc.find_parent_network("192.168.64.7")
        bc.create_address(parent_id=net["id"], address="192.168.64.7", type_="IPv4Address", name="a1-ev0c-arista")
    # initial_provision("a1-ev0c-arista", "t1-ev0c", 1)
    # arista_wipe_switch("t1-ev0c", 1)
    pass
